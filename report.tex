\documentclass[a4paper,10pt]{article}
%\usepackage[latin1]{inputenc}
%\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{enumerate}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{ifsym}
\usepackage{parskip}
\usepackage[numbers,sectionbib]{natbib}

% Egne kommandoer for enklere vektornotasjon
\renewcommand{\vec}[1]{\mathbf{#1}}
\renewcommand{\(}{\left(}
\renewcommand{\)}{\right)}
%\renewcommand{\>}{\right>}
%\renewcommand{\<}{\left<}
\newcommand{\dd}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
\newcommand{\ddd}[2]{\frac{\mathrm{d^2}#1}{\mathrm{d}#2^2}}
\newcommand{\dpart}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\dpartt}[2]{\frac{\partial^2#1}{\partial#2^2}}
\newcommand{\qqq}{\qquad\qquad\qquad}
\newcommand{\f}[2]{\frac{#1}{#2}}
\newcommand{\bs}[1]{$\boldsymbol #1$}
\newcommand{\bsa}[1]{\boldsymbol #1}
\usepackage{listings}
\usepackage{color}
\usepackage{textcomp}
\definecolor{listinggray}{gray}{0.9}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{
 backgroundcolor=\color{white},
 tabsize=4,
 rulecolor=,
 language=c++, 
 basicstyle=\scriptsize,
 upquote=true,
 aboveskip={1.5\baselineskip},
 columns=fixed,
 showstringspaces=false,
 extendedchars=true,
 breaklines=true,
 prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
 frame=single,
 showtabs=false,
 showspaces=false,
 showstringspaces=false,
 identifierstyle=\ttfamily,
 keywordstyle=\color[rgb]{0,0,1},
 commentstyle=\color[rgb]{0.133,0.545,0.133},
 stringstyle=\color[rgb]{0.627,0.126,0.941},
}
\usepackage{subfig}
%\usepackage{wrapfig}
\usepackage{epstopdf}

\title{Project 1 - INF5620}

\date{\today}
\author{Kand. Nr. 31}

\newenvironment{changemargin}[2]{%
 \begin{list}{}{%
 %\setlength{\topsep}{0pt}%
 \setlength{\leftmargin}{#1}%
 \setlength{\rightmargin}{#2}%
 %\setlength{\listparindent}{\parindent}%
 %\setlength{\itemindent}{\parindent}%
 %\setlength{\parsep}{\parskip}%
 }%
 \item[]}{\end{list}}
 
 \newcommand{\maxFigure}[4]{
 \begin{figure}[htp!]
 \begin{changemargin}{-3cm}{-1cm}
 \begin{center}
 %\includegraphics[width=\paperwidth + 3cm,height=\paperheight,keepaspectratio]{#2}
 \includegraphics[scale = #2]{#3}
 \end{center}
 \end{changemargin}
\vspace{-10pt}
  \caption{\textit{#1} }
  \label{#4}
 \end{figure}
 }
 
 \makeatletter
 \setlength{\abovecaptionskip}{6pt}   % 0.5cm as an example
\setlength{\belowcaptionskip}{6pt}   % 0.5cm as an example
% This does justification (left) of caption.
\long\def\@makecaption#1#2{%
  \vskip\abovecaptionskip
  \sbox\@tempboxa{#1: #2}%
  \ifdim \wd\@tempboxa >\hsize
    #1: #2\par
  \else
    \global \@minipagefalse
    \hb@xt@\hsize{\box\@tempboxa\hfil}%
  \fi
  \vskip\belowcaptionskip}
\makeatother
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% DOCUMENT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\section*{Abstract}
The two dimensional wave equation can be used to model many interesting problems such as electromagnetic waves and tsunami waves. We develop a numerical solver based on an explicit scheme and discuss algorithm validation, stability, visualization and techniques for complex geometries. MayaVi is used to visualize and we have written our own visualizer using OpenGL.

\section*{Theory}
The wave equation is quite powerful in the sense that it describes many important systems in physics. We have the general equation with damping coefficient $b$, wave velocity $q(x,y)$ and source $f(x,y,t)$ given as
\begin{align}
\frac{\partial^2 u}{\partial t^2} + b\frac{\partial u}{\partial t} =
\frac{\partial}{\partial x}\left( q (x,y)
\frac{\partial u}{\partial x}\right) +
\frac{\partial}{\partial y}\left( q (x,y)
\frac{\partial u}{\partial y}\right) + f(x,y,t),
\end{align}
or more compact
\begin{align}
\frac{\partial^2 u}{\partial t^2} + b\frac{\partial u}{\partial t} =
\nabla \cdot \big(q(x,y) \nabla u \big )
\end{align}
The velocity function $q(x,y)$ describes the wave propagation speed in the point $(x,y)$. For water waves, this can be interpreted as the depth $h$ at the point $(x,y)$ as water wave velocities behave like $c(h) \propto \sqrt h$. 
\subsection*{Boundary and initial conditions}
The equation is second order in time and space, so in order to have a unique solution, we need the initial condition $u(x,y,t=0) = I(x,y)$ and its derivative $\dpart{u}{t}|_{t=0}=V(x,y)$. In addition, when the wave hits a wall, we use the boundary condition
\begin{align}
\label{eq:boundary}
\nabla u\cdot \textbf n = 0 = \dpart{u}{n}
\end{align}
where $\dpart{u}{n}$ is the derivative in the direction normal to the boundary. 
\section*{Numerical implementation}
\subsection*{Discretization}
If we look at a system of widths $L_x$ and $L_y$, we can divide the system into a grid with $N_x\times N_y$ points where we have the steplengths $\Delta x=\f{L_x}{N_x-1}$ and $\Delta y=\f{L_y}{N_y-1}$. The wave function $u$ is now represented as a matrix $u_{i,j}$ where $u_{i,j}=u(x_i,y_j)$ in each timestep $t_n$. The numerical wave equation can be discretized on operator form
\begin{align*}
\Big[D_tD_t u + bD_{2t}u = D_x  q[D_x u] + D_y q [D_y u]\Big]^n_{i,j}
\end{align*}
where we have applied the standard approximation for second derivatives in time, the centered difference scheme on the first derivative and the Crank-Nicolson twice in the spatial part. Written out in full index form, this evaluates to
\begin{align*}
\text{L.H.S. } & = \f{u^{n+1}_{i,j} + u^{n-1}_{i,j} - 2u^{n}_{i,j}}{\Delta t^2} + b\f{u^{n+1}_{i,j}-u^{n-1}_{i,j}}{2\Delta t}\\
\text{R.H.S. } & = \f{1}{\Delta x}\Bigg(q_{i+\f{1}{2},j}\Bigg[\f{u^n_{i+1,j} - u^n_{i,j}}{\Delta x}\Bigg]
- q_{i-\f{1}{2},j}\Bigg[\f{u^n_{i,j} - u^n_{i-1,j}}{\Delta x}\Bigg]\Bigg)\\
&+\f{1}{\Delta y}\Bigg(q_{i,j+\f{1}{2}}\Bigg[\f{u^n_{i,j+1} - u^n_{i,j}}{\Delta y}\Bigg]
- q_{i,j-\f{1}{2}}\Bigg[\f{u^n_{i,j} - u^n_{i,j-1}}{\Delta y}\Bigg]\Bigg)
\end{align*}
This can be solved for $u_{i,j}^{n+1}$ and we can easily evolve the system in time. We notice that to calculate timestep $n+1$, we need both timesteps $n$ and $n-1$ because of the second derivative in time. This reflects the requirement of both $u(x,y,t=0) = I(x,y)$ and $u(x,y,t+\Delta t)$ as mentioned above. There are two standard ways to calculate the second timestep $u(x,y,0+\Delta t)$. If we have the initial condition $\dpart{u}{t}|_{t=0}=0$, we apply the forward difference scheme
\begin{align*}
\f{u^{+1}_{i,j} - u^{0}_{i,j}}{\Delta t} = 0\\
\end{align*}
which gives
\begin{align*}
u^{+1}_{i,j} = u^{0}_{i,j}
\end{align*}
for all $i,j$. If we have the more complicated and general system where $\dpart{u}{t}|_{t=0} = V(x,y)$, we can use the centered difference scheme and define
\begin{align*}
\f{u^{+1}_{i,j} - u^{-1}_{i,j}}{2\Delta t} = V(x_i,y_j)\\
\end{align*}
which gives
\begin{align*}
u^{-1}_{i,j} = u^{+1}_{i,j} + V_{i,j}
\end{align*}
where we evaluate $V_{i,j} = V(x_i,y_j)$. We can again solve the equation for $u_{i,j}^{+1}$ by using only one timestep. The second derivative in the spatial dimensions also require both neighbor points which will give problems at the boundaries where such points might not exist. We solve this by using \eqref{eq:boundary} and apply the centered difference scheme on $\dpart{u}{n}$, assuming that the normal vector is in either the $x$- or $y$-direction and define
\begin{align*}
\dpart{u}{x} = 0 = \f{u^n_{i+1,j} - u^n_{i-1,j} }{ 2\Delta x}
\end{align*}
which again gives
\begin{align}
\label{eq:boundary2}
u^n_{i-1,j} = u^n_{i+1,j}
\end{align}
These points are often called ghost points, or ghost cells, because they don't really exist.
\subsection*{More general boundary conditions}
If we have walls at the boundaries $u_{i,j} | i,j \in \{0,N_x-1\}$, we can easly do an if-test and apply \eqref{eq:boundary2}. The code will then be rather messy with special cases for each boundary, and the systems geometry is limited. We can instead introduce the wall matrix $W \in \mathbb B ^{N_x\times N_y}$ where $\mathbb B$ is the boolean domain. Each point $W_{i,j}$ contains either a \textit{true} or \textit{false} value defining if that point is a wall or not. To implement this method, we have the matrices $u\_$ and $u\_prev\_$ which contains all the values of $u$ in the two previous timesteps. In addition we have the wall matrix $W$ with booleans. When we access the elements $u_{i\pm 1,j}$ or $u_{i,j\pm 1}$, we create a function that returns the elements $u_{i\mp 1,j}$ or $u_{i,j\mp 1}$ if there is a wall at the respective point. The algorithm looks like
\begin{lstlisting}
int idx(int i) {
	return (i+10*Nr)\%Nr;
}

double u(int i,int j, int di, int dj) {
	if(W(idx(i+di),idx(j+dj))) {
		return u_(idx(i-di),idx(j-dj));
	} 

	return u_(idx(i+di),idx(j+dj));
}
\end{lstlisting}
\subsection*{Complex objects and varying $q(x,y)$}
By using the method above we can represent more complex objects and geometries by filling the wall matrix $W$ instead of making complicated special cases programmatically. One way to handle both boundary conditions and the wave velocity field $q(x,y)$ is to use BMP-images to represent the geometry of the system. If we create a black-and-white BMP-image of size $N_x\times N_y$ pixels, this can in our program be represented as a matrix $G \in \mathbb R ^{N_x\times N_y}$ where each value $G_{i,j} \in (0,1)$ containing the white level value in that point. This image can be used to define both boundaries (walls and objects) and ground (wave velocity) by choosing a threshold value $p$ such that $W_{i,j} = G_{i,j} \geq p$. By shifting the values $G_{i,j} \rightarrow G_{i,j}-p$, the value in $G$ can now be interpreted as the depth where values above zero will behave like hard boundaries and values below zero will affect the wave velocity.

\begin{lstlisting}
void calculateWalls() {
	for(int i=0;i<Nx;i++) {
		for(int j=0;j<Ny;j++) {
			walls(i,j) = ground(i,j) >= 0;
		}
	}
}

\end{lstlisting}
\subsection*{Source term and rain}
One application of source terms can be raindrops falling in the water. We create raindrops randomly at a height $z_0$ and let them fall with constant velocity. When the rain hits the surface, we increase the source term $f_{i,j}$ by a suitable value. 
\begin{lstlisting}
void moveRainDrops() {
    for(int k=0;k<raindrops.size();k++) {
        raindrops[k].z -= 0.005;

        if(raindrops[k].z <= u_(raindrops[k].i,raindrops[k].j)) {
            source(raindrops[k].i,raindrops[k].j) = 0.01;
            raindrops.erase(raindrops.begin()+k--);
        }
    }
}
This creates those beautiful ripples we expect from raindrops hitting the surface.
\end{lstlisting}
\section*{Verification}
\subsection*{Constant solution}
\subsection*{Exact 1D solution}
\subsection*{Standing wave}
By assuming a constant wave velocity $q(x,y)=k$, a solution to the equation is the standing wave
\begin{align*}
u(x,y,t) &= \exp(-bt)\cos\Big(\f{m_xx\pi}{L_x}\Big)\cos\Big(\f{m_yy\pi}{L_y}\Big)\cos{\omega t}\\
&= \exp(-bt)\cos (k_x x)\cos (k_y y)\cos{\omega t}
\end{align*}
for arbitrary integers $m_x$, $m_y$ and frequency $\omega$. This solution gives a rather messy source term $f(x,y,t)$, but it's trivial to calculate. We rewrite the solution to $u(x,y,t) = T(t)\cdot R(x,y)=T(t)\cdot X(x) \cdot Y(y)$
\begin{align*}
b\dd{T}{t} &= -e^{-bt}(b^2\cos \omega t + b\omega \sin \omega t)\\
\ddd{T}{t} &= e^{-bt}\Big[(b^2 - \omega^2)\cos\omega t + 2b\omega\sin\omega t\Big] \\
\ddd{X}{x} &= - k_x^2 X(x)
\end{align*}
The left hand side of the wave equation now reads
\begin{align*}
e^{-bt}R(x,y)&\Big[ (b^2 - \omega^2)\cos\omega t + 2b\omega\sin\omega t -b^2\cos \omega t - b\omega \sin \omega t \Big]\\
& = e^{-bt}R(x,y)\Big[-\omega^2\cos\omega t + b\omega\sin\omega t\Big]\\
& = u(x,y,t)\Big[-\omega^2 + b\omega\tan\omega t\Big]
\end{align*}
Which gives
\begin{align*}
u(x,y,t)\Big[-\omega^2 + b\omega\tan\omega t\Big] = -q\big[ k_x^2 + k_y^2 \big]u(x,y,t) + f(x,y,t)
\end{align*}
We can solve this for the source term
\begin{align*}
f(x,y,t) &= u(x,y,t)\Big[ k^2 - \omega^2 + b\omega \tan\omega t\Big]
\end{align*}
where $k^2=q(k_x^2 + k_y^2)$. If we choose this as the source term, we only need to calculate the first time derivative to have a unique solution.
\begin{align*}
V(x,y) &= \dpart{u(x,y,t)}{t}\Big|_{t=0} \\
& = -e^{-bt}(b\cos\omega t + \omega \sin\omega t)\cos(k_xx)\cos(k_yy)\Big|_{t=0}\\
&= -b\cos(k_xx)\cos(k_yy)
\end{align*}
The initial condition is 
\begin{align*}
I(x,y) &= u(x,y,t=0) = \cos(k_xx)\cos(k_yy)
\end{align*}

\section*{c++ implementation}
One of our extensions is to solve the given 2d wave problem by using C++ and its (almost) bult-in libraries std and boost. This is as simple as coding the problem in python,
as the syntax of the numerics is identical. One difference is that we have to use scalar programming as a vectorized form 
puts requirements on all called functions (e.g. double sin(double x) must be rewritten/overloaded to take a matrix as argument and also return a matrix). This is not a viable approach, but scalar programming
done correctly should also be quite readable as the numerics become very close to the mathematics.

We wrote most of the code directly in main(). This could easily be converted into a general class, but this requires a lot of assignment code and was not done for simplicity.
Also, most of the parameters are hardcoded and can be changed at the top of main(). The various input functions (i.e. I(x,y), V(x,y), q(x,y,t) and f(x,y,t)) can also be set at this point by assigning
the general function pointers to point to the relevant functions.

The increased complexity at the boundaries can easily be solved when using scalar programming. The r.h.s of equation TODO can now be evaluated by using four simple if-tests
\begin{align*}
&i \mp 1 \rightarrow i\pm 1, \ \ \ \rm if \ \ i \mp 1 \notin  [0,N_x]\\
&j \mp 1 \rightarrow j\pm 1, \ \ \ \rm if \ \ j \mp 1 \notin  [0,N_y]\\
\rm rhs = & \\
&\frac{1}{\Delta x^2} \left( c_{i+1/2,j} (u_{i+1,j} - u_{i,j}) - c_{i-1/2,j}(u_{i,j} - u_{i-1,j}) \right)  + \\
&\frac{1}{\Delta y^2} \left( c_{i,j+1/2} (u_{i,j+1} - u_{i,j}) - c_{i,j-1/2}(u_{i,j} - u_{i,j-1}) \right) + f(x,y,t),
\end{align*}
which is valid for all points in the entire grid ($[0,N_x][0,N_y]$) with von Neumann boundary conditions. With this we don't need specific formulas for the boundaries. This can also be done vectorized in python by
using ghost points, which is done in our python solver.

We implemented the solver by using the boost::numeric::ublas::matrix template class for the matrices. This removes the need for explicit double pointer 'arithmetics' in addition to manual memeory allocation and deallocation.
The syntax is easy
\begin{lstlisting}
 matrix<double> u(Nx, Ny); // create an Nx by Ny matrix
 u(0,6) = 5; // set element (0,6) equal to 5.
\end{lstlisting}
The contrast from double pointers is obvious u(i,j) $\equiv$ u[i][j]. The matrix class also overloades the arithmetic operators (+,-,*,/), thus allows vectorized syntax
\begin{lstlisting}
 matrix<double> u(Nx, Ny);
 matrix<double> v(Nx, Ny);
 ...
 u = u + v - 2*v;
\end{lstlisting}
This is not used in our code.


\section*{C++ parallelization}
An additional extension is to parallelize our implementation. We did this by using OpenMP, which is an API that supports shared memory multiprocessing in C, C++ and Fortran. 

Our implementation is easily parallelizable (at least to a certain extent). From the numerics, we can see that all calculations in a given timestep is idependent of eachother. That is, for a given n, all
calculations are only dependent on the previous timestep
\begin{align*}
\rm u_{\rm n} = \rm u_{\rm n }(\rm i, \rm j, u_{n-1}).
\end{align*}
This implies that the nested space loop is embarrassingly parallel. In OpenMP, the parallelization is done by a pragma directive
\begin{lstlisting}
// time loop
for (int n=1; n<Nt; n++) {
    // space loops
    #pragma omp parallel for
    for (int i=0; i<Nx; i++) // <-- this is parallelized
	for (int j=0; j<Ny; j++) // < -- all threads run this loop
	    unext(i,j) = ... something only dep. on n-1 ...
}
\end{lstlisting}
This code forks the outer spatial loop into $N_{\rm cores}$ threads, where $N_{\rm cores}$ is the number of CPU cores. The threads eavenly (if possible) divide the i interval [0,Nx) into $N_{\rm cores}$ intervals and runs the i-loop for these values of i.
At the end of the i-loop, the threads terminate and only the master thread continues execution. Since all threads share the same memory, the variables (declared before the loop) used by all threads are the same.
We could also only parallelize the innermost loop (i.e. the j-loop), but this would probably decrease the efficiency since the threads would be created and killed for each iteration i, 
thus creating more overhead.

\subsection*{Speedtests}

To check the efficiency of the parallelized code, we try a few runs with and without parallelization. We use the following spatial domains: $50 \times 50$, $100 \times 100$, $400 \times 400$. The results are (in seconds)
\begin{center}
   \begin{tabular}{| c || l | l | | l|}
    \hline 
    \# cores & 50x50 & 100x100 & 400x400 \\ \hline \hline
    1 & 0.89 & 3.54 & 57.1 \\ \hline 
    4 & 0.5 & 0.97 & 15.3\\ \hline  \hline 
    Ratio & 1.8 & 3.65 & 3.73 \\ \hline
   \end{tabular}
\end{center}
If the entire algorithm was completely parallelizable the ratio has a theoretical maximum ratio of $N_{\rm cores}$. We can see that the parallel code is about $3.7$ times faster. This makes sense, since the time loop
has not been touched. Also, we can see that the ratio falls with decreasing spatial domain size, which is probably due to increased overhead from thread creation/destruction compared to the gain from parallelization.
Larger spatial domain should increase the ratio further.
\section*{Error convergance}
We are given an exact solution to the 2d wave equation (1) in the project text. In this section, we study the numerical approximation of this solution. All the derivations of $I(x,y)$, $V(x,y)$ and $f(x,y,t)$ are
given in TODO. 

There are various ways to calculate the error of the approximation. We wanted to check the dependence of the error in spatial resolution, $\Delta x$ and $\Delta t$. We take $\Delta x = \Delta y \equiv h$ and $\Delta t = 0.1h$ 
to ensure stability. To calculate the error we used that for a given time
\begin{align*}
 E = h^2 \sqrt{\sum_{i,j}(u_{i,j} - u^{\rm exact}_{i,j})^2}.
\end{align*}
We expect that $E/h^2$ to be constant. 
\subsection*{Tests}
We chose the range of $h$ from $0.08$ to $0.004$ and calculated the error at time $t=1$. The results are listed in table \ref{tbl1}.
\begin{center}
   \begin{tabular}{| l || l | l|}
    \hline 
    $h$ & E & $E/h^2$ \\ \hline \hline
    $0.08 $ & 0.0179 & 2.80 \\ \hline 
    $0.04 $ & 0.00437 & 2.73 \\ \hline 
    $0.02$ & 0.00107 & 2.68 \\ \hline 
    $0.01$ & 0.000266 & 2.66  \\ \hline 
    $0.005$ & $5.52 \times 10^{-6}$ & 2.65 \\ \hline 
    $0.004$ &  & \\ \hline 
    
   \end{tabular}
   \label{tbl1}
\end{center}
We see that the factor $E/h^2$ is approximatly constant ($\approx 2.7$), as expect from error analysis. If we decrease $h$ by a factor of 2 the error decreases by a factor of $2^2 = 4$. Since the error
convergance behaves (TODO) as expected, the resolution of the agreement of extended pictures implies correctness of implementation.
\end{document}
